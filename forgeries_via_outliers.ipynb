{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forgeries.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWWlYDCdy5Wh",
        "outputId": "bf4fcf14-32cd-40b0-e524-6f5fa1acbfb0"
      },
      "source": [
        "!pip install umap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting umap\n",
            "  Downloading umap-0.1.1.tar.gz (3.2 kB)\n",
            "Building wheels for collected packages: umap\n",
            "  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3564 sha256=c75a93d42467a8f771a7e4716acb72790e0ce1d569e6d7810eb05d9aaaa08db5\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/55/85/945cfb3d67373767e4dc3e9629300a926edde52633df4f0efe\n",
            "Successfully built umap\n",
            "Installing collected packages: umap\n",
            "Successfully installed umap-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "m_v6QqD8upq0",
        "outputId": "b0a301d1-bdd5-46a5-d511-3c411e90f9ce"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.cluster import dbscan\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import OPTICS\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.base import ClusterMixin\n",
        "from sklearn.utils import check_array\n",
        "import matplotlib.pyplot as plt\n",
        "import umap\n",
        "\n",
        "csvs = ['prag_dates.csv', 'dates.csv', 'prag.csv', 'res.csv', 'ds_clumps.csv', 'ideology.csv', 'year.csv']\n",
        "\n",
        "df=pd.read_csv('./Newsbooks_Intermediary_Data/res.csv')\n",
        "\n",
        "features = ['AcademicTerms',\n",
        "       'AcademicWritingMoves', 'CharacterCognitiveAgency',\n",
        "       'CharacterCognitiveStates', 'CharacterDialogueCues',\n",
        "       'CharacterDisclosive', 'CharacterPersonNamesPronouns',\n",
        "       'CharacterSubjective', 'CharacterTraitsTypes', 'CitationAuthority',\n",
        "       'CitationControversy', 'CitationGeneral', 'CitationHedged',\n",
        "       'CitationNegative', 'CitationNeutral', 'CitationSpeakerLookMood',\n",
        "       'ConfidenceHedged', 'ConfidenceHigh', 'ConfidenceHighNegative',\n",
        "       'ConfidenceLow', 'Contingent', 'Description', 'Facilitate',\n",
        "       'FirstPerson', 'ForceStressed', 'Future', 'InformationChange',\n",
        "       'InformationChangeNegative', 'InformationChangePositive',\n",
        "       'InformationExposition', 'InformationPlace', 'InformationReportVerbs',\n",
        "       'InformationStates', 'InformationTopics', 'Inquiry', 'Interactive',\n",
        "       'MetadiscourseCohesive', 'MetadiscourseInteractive', 'NarrativeActs',\n",
        "       'NarrativeBiographicalTime', 'NarrativeDuration',\n",
        "       'NarrativeExpectation', 'NarrativeHurriedTime', 'NarrativeImmediacy',\n",
        "       'NarrativePast', 'NarrativeSceneShifts', 'NarrativeSequence',\n",
        "       'NarrativeSimultaneity', 'NarrativeTimeReference',\n",
        "       'NarrativeTimeShifts', 'NarrativeTrends', 'NarrativeTurningPoint',\n",
        "       'NarrativeVerbs', 'Negative', 'Orphaned', 'Positive', 'PublicTerms',\n",
        "       'Reasoning', 'Responsibility', 'Strategic', 'SyntacticComplexity',\n",
        "       'Uncertainty', 'Updates']\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a4e579fefa92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcsvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'prag_dates.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dates.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prag.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'res.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ds_clumps.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ideology.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Newsbooks_Intermediary_Data/res.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m features = ['AcademicTerms',\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Newsbooks_Intermediary_Data/res.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LovfvaWouyFg"
      },
      "source": [
        "complete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x33VqdKvuvMB"
      },
      "source": [
        "X = df[features]\n",
        "\n",
        "\n",
        "tsne_embedded = TSNE(n_components=2, metric='euclidean').fit_transform(X)\n",
        "pca_embedded = PCA(n_components=2).fit_transform(X)\n",
        "\n",
        "TSNE_df = pd.DataFrame(tsne_embedded)\n",
        "pca_df = pd.DataFrame(pca_embedded)\n",
        "\n",
        "reducer=umap.UMAP()\n",
        "umap_embedding=reducer.fit_transform(X) # takes 1-10 seconds\n",
        "umap_df=pd.DataFrame(umap_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf6kj6r7vCq_"
      },
      "source": [
        "clstr_dbscan_tsne=dbscan(tsne_embedded,eps=3.3) \n",
        "pd.DataFrame(clstr_dbscan_tsne[1]).describe()\n",
        "clstr_optics_tsne=OPTICS(min_samples=.1).fit_predict(tsne_embedded)\n",
        "plt.scatter(TSNE_df[0],TSNE_df[1],c=clstr_dbscan_tsne[1])\n",
        "plt.show()\n",
        "plt.scatter(TSNE_df[0],TSNE_df[1],c=clstr_optics_tsne)\n",
        "plt.show()\n",
        "plt.scatter(pca_df[0],pca_df[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f3rFhyEvPJY"
      },
      "source": [
        "\n",
        "\n",
        "> helpers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySQiBn7dvOPL"
      },
      "source": [
        "def dfNormalizer(df):\n",
        "    xmin=np.array(df[0]).min()\n",
        "    xdif=np.array(df[0]).max()-xmin\n",
        "    ymin=np.array(df[1]).min()\n",
        "    ydif=np.array(df[1]).max()-ymin\n",
        "    resx=[]\n",
        "    resy=[]\n",
        "    for xelement in df[0]:\n",
        "        xelement=(xelement - xmin)/xdif\n",
        "        resx.append(xelement)\n",
        "\n",
        "    for yelement in df[1]:\n",
        "        yelement=(yelement - ymin)/ydif\n",
        "        resy.append(yelement)\n",
        "\n",
        "    res=pd.DataFrame(zip(resx,resy))\n",
        "\n",
        "    return res\n",
        "\n",
        "def pdNormalizer(ndarray):\n",
        "    return dfNormalizer(pd.DataFrame(ndarray)).to_numpy()\n",
        "def showplot(ndarr,cluster):\n",
        "    plt.scatter(pd.DataFrame(ndarr)[0],pd.DataFrame(ndarr)[1],c=cluster)\n",
        "    plt.show()\n",
        "def createz(title):\n",
        "       res=[]\n",
        "       arr=df[title]\n",
        "\n",
        "       mu= np.mean(arr)\n",
        "       sigma=np.std(arr)\n",
        "       for item in arr:\n",
        "              z= abs( (item - mu)/sigma)\n",
        "              res.append(z)\n",
        "       return np.array(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05MBG1_lvgLQ"
      },
      "source": [
        "def findForgeries(newsbookstitle:str):\n",
        "       print(f\"TITLE:{newsbookstitle}\")\n",
        "       nb=df[df[\"Newsbooks Title\"].str.match(newsbookstitle)][features]\n",
        "       names=pd.DataFrame(df[df[\"Newsbooks Title\"].str.match(newsbookstitle)][\"text_name\"])\n",
        "       print(nb.shape)\n",
        "       if nb.shape[0]<5:\n",
        "              return\n",
        "       \n",
        "       nbtsne=TSNE(n_components=2, metric='euclidean').fit_transform(nb)\n",
        "       nbpca = PCA(n_components=2).fit_transform(nb)\n",
        "       nbumap = umap.UMAP().fit_transform(nb)\n",
        "\n",
        "       normalized_tsne=dfNormalizer(nbtsne)\n",
        "       normalized_pca=dfNormalizer(nbpca)\n",
        "       normalized_umap=dfNormalizer(nbumap)\n",
        "\n",
        "       \n",
        "       optics_tsne=OPTICS(min_samples=.5).fit_predict(nbtsne)\n",
        "       optics_pca=OPTICS(min_samples=.5).fit_predict(nbpca)\n",
        "       # optics_umap=OPTICS(min_samples=.5).fit_predict(nbumap)\n",
        "       \n",
        "       dbscan_pca=dbscan(nbpca,eps=.5)\n",
        "      \n",
        "       showplot(nbtsne,optics_tsne)\n",
        "\n",
        "       showplot(nbpca,optics_pca)\n",
        "       showplot(nbumap,optics_umap)\n",
        "       showplot(nbpca,dbscan_pca[1])\n",
        "\n",
        "      #   names[\"tnse\"]=list(nbtsne)\n",
        "      #  names[\"pca\"]=list(nbpca)\n",
        "      #  print(names)\n",
        "\n",
        "       # showplot(normalized_tsne,optics_tsne)\n",
        "       # showplot(normalized_pca,optics_pca)\n",
        "       # showplot(normalized_umap,optics_umap)\n",
        "       # showplot(normalized_pca,dbscan)\n",
        "\n",
        "       return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_y3tHO3vgU1"
      },
      "source": [
        "sampletitle=\"The kingdomes vveekly intelligencer\"\n",
        "sampletitle2=\"Mercurius pragmaticus\"\n",
        "findForgeries(sampletitle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lplrploRykyP"
      },
      "source": [
        "for name in df[\"Newsbooks Title\"].unique():\n",
        "    findForgeries(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RX8momdzmpH"
      },
      "source": [
        "title\tconfidence\ttext name\treason\tnotes:\t\n",
        "mercurius elencticus\tslight\t43_clean\tpca\tall of the other \"mercurius electencus\" have text names 555-584\t\n",
        "mercurius elencticus\tslight\t44_clean\tpca\t\t\n",
        "mercurius elencticus\tslight\t45_clean\tpca\t\t\n",
        "the kingdomes faithful inpartial\tslight\t72_clean\tpca\t\t\n",
        "The kingdomes vveekly intelligencer\tmedium\t188_clean\tpca\tsame sit as elenctucus\t\n",
        "The kingdomes vveekly intelligencer\tmedium\t189_clean\tpca\t\t\n",
        "The kingdomes vveekly intelligencer\tslight\t216_clean\tpca\t\t\n",
        "The man in the moon\thigh\t238_clean\ttsne\t\t\n",
        "The moderate intelligencer\tslight\t270_clean\tpca\t\t\n",
        "A briefe relation of some affaires\thigh\t308_clean\tpca\t\t\n",
        "A briefe relation of some affaires\tmedium\t320_clean\tpca\t\t\n",
        "Perfect occurrences of every dayes\tmedium\t340_clean\tpca\tsame sit\t\n",
        "Perfect occurrences of every dayes\tmedium\t341_clean\tpca\t\t\n",
        "Severall proceedings in Parliament\thigh\t389_clean\tpca\t\t\n",
        "A perfect summary of exact passages\tmedium\t396_clean\tpca\t\t\n",
        "A perfect diurnall of some passages\tslight\t511_clean\tpca\t\t\n",
        "A perfect diurnall of some passages\tslight\t512_clean\tpca\t\t"
      ]
    }
  ]
}